import gradio as gr
import os
import time
from dotenv import load_dotenv
from app.core.rag_chain import prepare_vector_store, rag_qa, get_qa_chain, DeepSeekLLMWrapper
import logging

load_dotenv()
logger = logging.getLogger(__name__)

# å…¨å±€çŠ¶æ€
state = {
    "qa_chain": None,
    "doc_metas": None,
    "ready": False
}


def init_system():
    try:
        DATA_DIR = os.getenv("DATA_DIR", "data")
        INDEX_PATH = os.getenv("INDEX_PATH", "vector_store")

        yield "ğŸš€ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."
        yield "ğŸ”„ åŠ è½½å‘é‡çŸ¥è¯†åº“..."
        vector_store, doc_metas, _ = prepare_vector_store(DATA_DIR, INDEX_PATH)

        yield "ğŸ§  åˆå§‹åŒ–DeepSeekæ¨¡å‹..."
        llm = DeepSeekLLMWrapper()
        state["qa_chain"] = get_qa_chain(vector_store, llm)
        state["doc_metas"] = doc_metas

        # æµ‹è¯•è¿æ¥ - ä½¿ç”¨æ–°çš„ invoke æ–¹æ³•
        test_response = state["qa_chain"].invoke({"query": "ä½ å¥½ï¼Œè¯·å›å¤'ç³»ç»Ÿå°±ç»ª'"})["result"]
        if "ç³»ç»Ÿå°±ç»ª" not in test_response:
            raise ConnectionError(f"æ¨¡å‹è¿æ¥å¤±è´¥: {test_response}")

        state["ready"] = True
        yield "âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼"

    except Exception as e:
        state["ready"] = False
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        yield f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}"


def answer_question(question, history):
    if not state["ready"]:
        return "ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆç‚¹å‡»'åˆå§‹åŒ–ç³»ç»Ÿ'", []

    try:
        start_time = time.time()
        answer, sources = rag_qa(
            question,
            state["qa_chain"],
            state["doc_metas"]
        )
        response_time = time.time() - start_time

        # æ ¼å¼åŒ–å›ç­”
        formatted_answer = f"{answer}\n\n---\nâ±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’"
        return formatted_answer, sources

    except Exception as e:
        logger.error(f"å›ç­”é—®é¢˜é”™è¯¯: {str(e)}")
        return f"é”™è¯¯: {str(e)}", []


def format_source(source):
    """æ ¼å¼åŒ–æ¥æºæ–‡æ¡£æ˜¾ç¤º"""
    return f"""
**æ¥æº**: {source['source']}
**è·¯å¾„**: {source['file_path']}
**å†…å®¹**: {source['content'][:200]}{'...' if len(source['content']) > 200 else ''}
"""

with gr.Blocks(title="è¡Œä¸šçŸ¥è¯†é—®ç­”ç³»ç»Ÿ - DeepSeek RAG", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ§  è¡Œä¸šçŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    gr.Markdown("åŸºäºDeepSeek RAGæŠ€æœ¯çš„å‚ç›´é¢†åŸŸæ™ºèƒ½é—®ç­”")

    with gr.Row():
        with gr.Column(scale=1):
            init_btn = gr.Button("åˆå§‹åŒ–ç³»ç»Ÿ", variant="primary")
            init_status = gr.Textbox(label="ç³»ç»ŸçŠ¶æ€", interactive=False)
        with gr.Column(scale=3):
            gr.Markdown("### ä½¿ç”¨è¯´æ˜")
            gr.Markdown("1. ç‚¹å‡»'åˆå§‹åŒ–ç³»ç»Ÿ'æŒ‰é’®åŠ è½½çŸ¥è¯†åº“å’Œæ¨¡å‹")
            gr.Markdown("2. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†æé—®")
            gr.Markdown("3. ç³»ç»Ÿå°†åŸºäºè¡Œä¸šçŸ¥è¯†åº“å›ç­”")

    with gr.Row():
        chatbot = gr.Chatbot(
            height=500,
            avatar_images=(
                os.path.join(os.path.dirname(__file__), "assets", "user.jpg"),
                os.path.join(os.path.dirname(__file__), "assets", "bot.png")
            ),
            type="messages"
        )

    msg = gr.Textbox(label="è¾“å…¥é—®é¢˜", placeholder="è¯·è¾“å…¥è¡Œä¸šç›¸å…³é—®é¢˜...", lines=2)

    with gr.Row():
        submit_btn = gr.Button("æäº¤é—®é¢˜", variant="primary")
        clear_btn = gr.ClearButton([msg, chatbot])

    with gr.Accordion("æ¥æºæ–‡æ¡£è¯¦æƒ…", open=False):
        source_display = gr.JSON(label="æ£€ç´¢ç»“æœ", show_label=False)  # ç»“æ„åŒ–å±•ç¤º

    gr.Examples(
        examples=["è¡Œä¸šæ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ", "æŠ€æœ¯è§„èŒƒæœ‰å“ªäº›ï¼Ÿ", "è®¾å¤‡æ“ä½œæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"],
        inputs=msg,
        label="ç¤ºä¾‹é—®é¢˜"
    )

    # äº‹ä»¶å¤„ç†
    init_btn.click(
        init_system,
        outputs=init_status
    )


    def respond(question, chat_history):
        response, sources = answer_question(question, chat_history)
        # ä½¿ç”¨æ–°çš„æ¶ˆæ¯æ ¼å¼
        chat_history.append({
            "role": "user",
            "content": question
        })
        chat_history.append({
            "role": "assistant",
            "content": response
        })
        return "", chat_history, sources


    msg.submit(
        respond,
        [msg, chatbot],
        [msg, chatbot, source_display]
    )

    submit_btn.click(
        respond,
        [msg, chatbot],
        [msg, chatbot, source_display]
    )

if __name__ == "__main__":
    demo.launch(
        server_port=8899,
        auth=(os.getenv("WEB_USER", "admin"), os.getenv("WEB_PASS", "password")),
        share=False,
        show_error=True
    )